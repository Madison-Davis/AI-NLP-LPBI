# -*- coding: utf-8 -*-
"""LPBI: Bar Graphs (V2).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BdlI3dqfVU265RJGAI7mZBBkkKmln9G4
"""

!pip install selenium 
from matplotlib import pyplot as plt
from collections import Counter
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords  
from nltk.tokenize import word_tokenize

# ------------------------ VARIABLES ------------------------ #
articles = []
other_stop_words = ["(mim","j","5","2,","(tnf","fig.","b.","a.","â\x86µ","4","9", "16","andâ\x80","(2011);","ã\x97","ut","wdr5","tx", "77030,", "[1-13c]",")","1,","Ê", "j.", "jihye","î\x9432","\\","clickâ\x84¢","hottest","ci:", "dl","(ie,","tc","why?","israelâ\x80\x99s","coming","intelligence:","together,", "a.i.","peâ\x80\x99er","https://www.forbes.com/sites/gilpress/2018/09/24/the-thriving-ai-landscape-in-israel-and-what-it-means-for-global-ai-competition/#577a107330c5","https://hackernoon.com/israels-artificial-intelligence-landscape-2018-83cdd4f04281","executiveâ\x80\x99s","â\x86\x92","s,","doi","6", "...", "body,","(its",".","body,","b","[â\x80¦]","actually", "25-27,","p.","a.,", "n3xt","see", "still","chiâ\x80\x99s","on:", "by:","ï\x82·","instituteâ\x80\x99s","phd,","tells","35","duodna,","2015)","2016)","(","0","15","28","synthegoâ\x80\x99s","itâ\x80\x99s","ja","2", "says", "lev-ariâ\x80\x8f","=","rec","th.","http://www.mdtmag.com/news/2015/10/top-10-medical-innovations-2016?et_cid=4908636&et_rid=461755519&type=image", "â\x9c\x93","e.","watch","thing", "want","got","going","-","that's","really","tf","broadâ\x80\x99s","â\x80\x93","intelliaâ\x80\x99s","broadâ\x80\x99s", "â\x80\x9cwe", "already","rn","vs","1","|","wherein","(uc","ma","said","every","ma","using","would","like","us","pgf2î±","â\x80\x9ccrispr-cas9","new", "dr.", "crisprâ\x80\x93cas","â\x80\x94", "il-1î²", ",", "â\x80¢", "&", "ê", "*", "â", "may", "form", "a,", "the", "al.", "al,", "al.,", "et", "c", "tov", "(fig.", "also", "md,", "curator:", "larry", "m.", "cells,", "could", "cell", "one", "two", "among", "able", "cancer,", "acquired", "h.", "must", "identified","and","or","et"]
 
# ------------------------ READ FILES ------------------------ #
 
for article in range(20):
 article_number = str(article + 1)
 path = '/content/sample_data/Data/Vol2-6.10.'+ article_number + '.txt'
 with open(path, encoding ='ISO-8859-1') as fopen:
   article = fopen.read()
   articles.append(article)
 
# ------------------------ FREQUENCY ------------------------ #
 
def frequency(str):
 text = str.lower().split()
 dictionary = {}
 # add all words to the dictionary
 for word in text:
   if word not in dictionary:
     dictionary[word] = 1
   else:
     number = dictionary.get(word) + 1
     dictionary.update({word : number})
 
 # after the loop, get rid of unecessary words
 stop_words = set(stopwords.words('english'))
 delete = [key for key in dictionary if key in stop_words or key in other_stop_words]
 for key in delete: del dictionary[key]
 
 # after the loop, get rid of any dictionary items that have only appeared ___ amount of times
 # let's say we want 10 words on our plot.  
 dictionary = dict(Counter(dictionary).most_common(10))
 print(dictionary)
 return dictionary
# ------------------------ PLOTTING ------------------------ #
 
article = 1
for i in range(20):
 fig, axs = ig, ax = plt.subplots(figsize=(25, 5))
 
 
 dictionary = frequency(articles[article - 1])
 # sort items by largest frequency
 dictionary = dict(sorted(dictionary.items(), key = lambda kv: kv[1], reverse = True))
 title = "Genomics Section 6.10 Article ", str(article), " Bar Graph: Word Frequency"
 keys = dictionary.keys()
 values = dictionary.values()
 
 axs.set_title(title)
 axs.bar(keys, values, color = (0.75,0.5,0.2,0.9))
 article = article + 1 
plt.show()